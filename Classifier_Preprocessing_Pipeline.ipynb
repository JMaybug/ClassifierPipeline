{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, average_precision_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "dataset_name = \"titanic.csv\"\n",
    "\n",
    "root_path = \"https://raw.githubusercontent.com/matzim95/ML-datasets/master/\"\n",
    "path_to_data = root_path + dataset_name\n",
    "df = pd.read_csv(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Peuchen, Major. Arthur Godfrey</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113786</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>C104</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>685</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Brown, Mr. Thomas William Solomon</td>\n",
       "      <td>male</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29750</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Lam, Mr. Ali</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mockler, Miss. Helen Mary \"Ellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330980</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Trout, Mrs. William H (Jessie L)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240929</td>\n",
       "      <td>12.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "449          450         1       1     Peuchen, Major. Arthur Godfrey    male   \n",
       "684          685         0       2  Brown, Mr. Thomas William Solomon    male   \n",
       "692          693         1       3                       Lam, Mr. Ali    male   \n",
       "359          360         1       3  Mockler, Miss. Helen Mary \"Ellie\"  female   \n",
       "399          400         1       2   Trout, Mrs. William H (Jessie L)  female   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
       "449  52.0      0      0  113786  30.5000  C104        S  \n",
       "684  60.0      1      1   29750  39.0000   NaN        S  \n",
       "692   NaN      0      0    1601  56.4958   NaN        S  \n",
       "359   NaN      0      0  330980   7.8792   NaN        Q  \n",
       "399  28.0      0      0  240929  12.6500   NaN        S  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name has been removed from analysis\n",
      "Column PassengerId has been removed from analysis.\n",
      "Columns with all unique values:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Delete all-unique ID columns\n",
    "\n",
    "def is_column_unique(col):\n",
    "    return col.nunique() == len(col)\n",
    "\n",
    "unique_columns = df.apply(is_column_unique, axis=0)\n",
    "unique_columns_list = unique_columns[unique_columns].index.tolist()\n",
    "\n",
    "while len(unique_columns_list) > 0:\n",
    "    id_present = ''\n",
    "    id_present = input(f'Found columns with all unique values: {unique_columns_list}. Does the list contain ID column/s? (y/n)')\n",
    "    \n",
    "    if id_present == 'y':\n",
    "        if len(unique_columns_list) == 1:\n",
    "            df.drop(unique_columns_list[0], axis = 1, inplace = True)\n",
    "            print(f\"Column {unique_columns_list[0]} has been removed from analysis.\")\n",
    "        else:    \n",
    "            id_col_name = input(str((f\"Please select the id column, so that it is deleted from analysis: {unique_columns_list}.\")))\n",
    "            df.drop(id_col_name, axis = 1, inplace = True)\n",
    "            print(f\"Column {id_col_name} has been removed from analysis\")\n",
    "    else: break\n",
    "    unique_columns = df.apply(is_column_unique, axis=0)\n",
    "    unique_columns_list = unique_columns[unique_columns].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Columns with all unique values:\")\n",
    "print(unique_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of available columns: ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(\"The list of available columns:\", list(df.columns))\n",
    "\n",
    "label_col = str(input(f'The dataframe has following columns: {list(df.columns)}.\\nSelect the labels (Y) column: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows deleted: 708\n",
      "Percentage of database deleted: 79.46%\n"
     ]
    }
   ],
   "source": [
    "# Dropping NAs\n",
    "\n",
    "# List of common missing value expressions\n",
    "missing_values = ['?', 'n/a', 'NA', \"nan\", 'null', '-', '']\n",
    "\n",
    "# Replace missing value expressions with NaN\n",
    "df.replace(missing_values, np.nan, inplace=True)\n",
    "\n",
    "# Count the number of rows before dropping\n",
    "total_rows_before = df.shape[0]\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_dropped = df.dropna()\n",
    "\n",
    "# Count the number of rows after dropping\n",
    "total_rows_after = df_dropped.shape[0]\n",
    "\n",
    "# Calculate the number of rows deleted and its percentage\n",
    "rows_deleted = total_rows_before - total_rows_after\n",
    "percentage_deleted = (rows_deleted / total_rows_before) * 100\n",
    "\n",
    "dropping = ''\n",
    "if rows_deleted > 0:\n",
    "    dropping = input(F\"Warning! The database contains {rows_deleted} rows with MISSING VALUES. It makes {percentage_deleted:.2f}% of the database.\\nWould you like to delete these rows? (y/n)\")\n",
    "    if dropping == 'y':\n",
    "        df = df_dropped.copy()\n",
    "        print(f\"Number of rows deleted: {rows_deleted}\")\n",
    "        print(f\"Percentage of database deleted: {percentage_deleted:.2f}%\")\n",
    "    else:\n",
    "        print('Proceeding without dropping the missing values. The missing values are replaced with zeros.')\n",
    "        df.replace(np.nan, 0, inplace=True)\n",
    "else: print(\"No missing values found in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found in the database.\n"
     ]
    }
   ],
   "source": [
    "# Dropping duplicates\n",
    "\n",
    "# Count the number of duplicate rows before dropping\n",
    "total_duplicates_before = df.duplicated().sum()\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_deduplicated = df.drop_duplicates()\n",
    "\n",
    "# Count the number of rows after dropping duplicates\n",
    "total_duplicates_after = df.shape[0] - df_deduplicated.shape[0]\n",
    "\n",
    "# Calculate the number of duplicate rows deleted and its percentage\n",
    "if total_duplicates_before > 0:\n",
    "    duplicates_deleted = total_duplicates_before - total_duplicates_after\n",
    "    percentage_duplicates_deleted = (duplicates_deleted / total_duplicates_before) * 100\n",
    "else:\n",
    "    duplicates_deleted = 0\n",
    "    percentage_duplicates_deleted = 0\n",
    "\n",
    "dropping = ''\n",
    "if duplicates_deleted > 0:\n",
    "    dropping = input(f\"Warning! The database contains {duplicates_deleted} DUPLICATE ROWS. It makes {percentage_duplicates_deleted:.2f}% of the database.\\nWould you like to delete these rows? (y/n)\")\n",
    "    if dropping == 'y':\n",
    "        df = df_deduplicated.copy()\n",
    "        print(f\"Number of duplicate rows deleted: {duplicates_deleted}\")\n",
    "        print(f\"Percentage of duplicates deleted: {percentage_duplicates_deleted:.2f}%\")\n",
    "    else:\n",
    "        print('Proceeding without dropping duplicate rows.')\n",
    "else:\n",
    "    print('No duplicate rows found in the database.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      int64\n",
      "Pclass        int64\n",
      "Sex          object\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Parch         int64\n",
      "Ticket       object\n",
      "Fare        float64\n",
      "Cabin        object\n",
      "Embarked     object\n",
      "dtype: object\n",
      "['Survived', 'Pclass', 'SibSp', 'Parch']\n"
     ]
    }
   ],
   "source": [
    "# Identify columns containing only integers\n",
    "integer_columns = []\n",
    "for col in df.columns:\n",
    "    if df[col].apply(lambda x: isinstance(x, (int, bool, str)) and re.match(r'^-?\\d+$', str(x)) is not None).all():\n",
    "        integer_columns.append(col)\n",
    "\n",
    "# Convert identified columns to numeric dtype\n",
    "for col in integer_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Print updated dtypes\n",
    "print(df.dtypes)\n",
    "\n",
    "print(integer_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(label_col, axis=1).copy()\n",
    "y = df[label_col]\n",
    "label_list = list(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Columns:\n",
      "['Age', 'Fare']\n",
      "\n",
      "Categorical Columns:\n",
      "['Pclass', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# X encoding\n",
    "\n",
    "threshold_percentage = 0.9  # 90%\n",
    "unique_values_threshold = 6\n",
    "\n",
    "# Step 1: Attempt to convert columns with mixed types to numeric where possible\n",
    "def try_convert_to_numeric(column):\n",
    "    return pd.to_numeric(column, errors='coerce')\n",
    "\n",
    "# Step 2: Determine whether a column is numeric based on the threshold\n",
    "def is_numeric_column(column, threshold_percentage):\n",
    "    column_numeric = try_convert_to_numeric(column)\n",
    "    num_numeric = column_numeric.notna().sum()\n",
    "    return (num_numeric / len(column)) >= threshold_percentage\n",
    "\n",
    "# Step 3: Classify columns and drop non-numeric values from numeric columns\n",
    "numeric_columns = []\n",
    "categorical_columns = []\n",
    "\n",
    "for col in X.columns:\n",
    "    if is_numeric_column(X[col], threshold_percentage):\n",
    "        column_numeric = try_convert_to_numeric(X[col])\n",
    "        if column_numeric.nunique() < unique_values_threshold:\n",
    "            categorical_columns.append(col)\n",
    "        else:\n",
    "            numeric_columns.append(col)\n",
    "            # Drop non-numeric values from numeric columns\n",
    "            X[col] = column_numeric\n",
    "    else:\n",
    "        categorical_columns.append(col)\n",
    "\n",
    "# Print the columns\n",
    "print(\"Numeric Columns:\")\n",
    "print(numeric_columns)\n",
    "\n",
    "print(\"\\nCategorical Columns:\")\n",
    "print(categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Column after dropping:\n",
      "['Age', 'Fare']\n",
      "\n",
      "Categorical Columns after dropping:\n",
      "['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns_toformat = []\n",
    "threshold_categories = 15\n",
    "for col in categorical_columns:\n",
    "    if len(list(X[col].unique())) > threshold_categories:\n",
    "        categorical_columns_toformat.append(col)\n",
    "\n",
    "if categorical_columns_toformat:\n",
    "    dropping = ''\n",
    "    dropping = input(f\"Warning! Found {len(categorical_columns_toformat)} categorical columns where the number of categories is higher than {threshold_categories}: {categorical_columns_toformat}. You may need to check the formatting of the columns. Drop the columns for the analysis? (y/n)\")\n",
    "    if dropping == 'y':\n",
    "        X.drop(categorical_columns_toformat, axis=1, inplace=True)\n",
    "\n",
    "        numeric_columns = []\n",
    "        categorical_columns = []\n",
    "\n",
    "        for col in X.columns:\n",
    "            if is_numeric_column(X[col], threshold_percentage):\n",
    "                column_numeric = try_convert_to_numeric(X[col])\n",
    "                if column_numeric.nunique() < unique_values_threshold:\n",
    "                    categorical_columns.append(col)\n",
    "                else:\n",
    "                    numeric_columns.append(col)\n",
    "                    # Drop non-numeric values from numeric columns\n",
    "                    X[col] = column_numeric\n",
    "            else:\n",
    "                categorical_columns.append(col)\n",
    "\n",
    "        # Print the columns\n",
    "        print(\"Numeric Column after dropping:\")\n",
    "        print(numeric_columns)\n",
    "\n",
    "        print(\"\\nCategorical Columns after dropping:\")\n",
    "        print(categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass       int64\n",
      "Sex         object\n",
      "SibSp        int64\n",
      "Parch        int64\n",
      "Embarked    object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "The labels of column Pclass are numerical.\n",
      "The values of column Sex are not numerical and have been encoded.\n",
      "Reference Table of Sex:\n",
      "male -> 0\n",
      "female -> 1\n",
      "\n",
      "\n",
      "The labels of column SibSp are numerical.\n",
      "The labels of column Parch are numerical.\n",
      "The values of column Embarked are not numerical and have been encoded.\n",
      "Reference Table of Embarked:\n",
      "S -> 0\n",
      "C -> 1\n",
      "Q -> 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "if categorical_columns:\n",
    "    print(X[categorical_columns].dtypes)\n",
    "    print(\"\\n\")\n",
    "    integer_dtypes = [int, np.int8, np.int16, np.int32, np.int64, \n",
    "                    np.uint, np.uint8, np.uint16, np.uint32, np.uint64,\n",
    "                    float, np.float16, np.float32, np.float64]\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        if X[col].dtype not in integer_dtypes:\n",
    "            # Step 1: Initialize and fit the LabelEncoder\n",
    "            original_labels = X[col].unique()\n",
    "            encoder = LabelEncoder()\n",
    "            X[col] = encoder.fit_transform(X[col])\n",
    "\n",
    "            # Step 2: Extract the original labels and their corresponding encoded values\n",
    "            \n",
    "            encoded_values = list(range(len(original_labels)))\n",
    "\n",
    "            # Step 3: Create and display the reference table\n",
    "            reference_table = dict(zip(original_labels, encoded_values))\n",
    "\n",
    "            print(f\"The values of column {col} are not numerical and have been encoded.\\nReference Table of {col}:\")\n",
    "            for label, encoded in reference_table.items():\n",
    "                print(f\"{label} -> {encoded}\")\n",
    "            print('\\n')\n",
    "        else:\n",
    "            print(f'The labels of column {col} are numerical.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical data has been normalized.\n"
     ]
    }
   ],
   "source": [
    "scaling = ''\n",
    "scaling = input(\"Scale the numerical data using the StandardScaler? (y/n)\")\n",
    "if scaling == \"y\":\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X[numeric_columns])\n",
    "    X[numeric_columns] = scaler.transform(X[numeric_columns])\n",
    "    print(\"Numerical data has been normalized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is balanced.\n",
      "\n",
      "           counts  percentage\n",
      "Survived                    \n",
      "1            123       67.21\n",
      "0             60       32.79\n"
     ]
    }
   ],
   "source": [
    "# Checking for label balance\n",
    "\n",
    "try:\n",
    "    label_counts = pd.concat([y.value_counts(), \n",
    "                y.value_counts(normalize=True).mul(100).round(2)],axis=1, keys=('counts','percentage'))\n",
    "except:\n",
    "    print(\"Error, check the labels column.\")\n",
    "\n",
    "unbalanced = False\n",
    "label_low = {}\n",
    "for i in range(len(label_list)):\n",
    "    if label_counts['percentage'].iloc[i] <= 10:\n",
    "        label_low[label_list[i]] = label_counts['percentage'].iloc[i]\n",
    "        unbalanced = True\n",
    "\n",
    "if unbalanced:\n",
    "    print('Warning! The dataset is unbalanced in terms of labels!\\n')\n",
    "    for i in label_low:\n",
    "        print(i,\"makes\",label_low[i],'% of the dataset.')\n",
    "else:\n",
    "    print('The dataset is balanced.')\n",
    "\n",
    "print(\"\\n\",label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels are not numerical and have been encoded.\n",
      "\n",
      "Reference Table:\n",
      "1 -> 0\n",
      "0 -> 1\n"
     ]
    }
   ],
   "source": [
    "# Label encoding\n",
    "\n",
    "if y.any != int:\n",
    "    # Step 1: Initialize and fit the LabelEncoder\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y)\n",
    "\n",
    "    # Step 2: Extract the original labels and their corresponding encoded values\n",
    "    original_labels = label_list\n",
    "    encoded_values = list(range(len(original_labels)))\n",
    "\n",
    "    # Step 3: Create and display the reference table\n",
    "    reference_table = dict(zip(original_labels, encoded_values))\n",
    "\n",
    "    print(\"The labels are not numerical and have been encoded.\\n\\nReference Table:\")\n",
    "    for label, encoded in reference_table.items():\n",
    "        print(f\"{label} -> {encoded}\")\n",
    "else:\n",
    "    print('The labels are numerical.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[label_col+\" (Label)\"] = y\n",
    "df = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns.append(label_col + \" (Label)\")\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as file: titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the summary DataFrame to a CSV file\n",
    "filename = input(\"Save the processed data? If yes, provide the name for csv file: \")\n",
    "\n",
    "if filename:\n",
    "    df.to_csv(f'{filename}.csv', index=False)\n",
    "    print(f\"Data saved as file: {filename}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
